{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0, MobileNetV2, ResNet50\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T10:34:15.881755Z","iopub.execute_input":"2025-05-16T10:34:15.882425Z","iopub.status.idle":"2025-05-16T10:34:15.886589Z","shell.execute_reply.started":"2025-05-16T10:34:15.882401Z","shell.execute_reply":"2025-05-16T10:34:15.885888Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import tensorflow as tf\n\n# Enable memory growth for all GPUs\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n\n\n# Load metadata\ndf = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T10:34:15.887586Z","iopub.execute_input":"2025-05-16T10:34:15.888342Z","iopub.status.idle":"2025-05-16T10:34:15.920578Z","shell.execute_reply.started":"2025-05-16T10:34:15.888324Z","shell.execute_reply":"2025-05-16T10:34:15.919813Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def get_image_path(image_id):\n    p1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/\"\n    p2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2/\"\n    return os.path.join(p1 if os.path.exists(p1 + image_id + \".jpg\") else p2, image_id + \".jpg\")\n\ndf[\"image_path\"] = df[\"image_id\"].apply(get_image_path)\nlabels = sorted(df[\"dx\"].unique())\nlabel_map = {l: i for i, l in enumerate(labels)}\ndf[\"label\"] = df[\"dx\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T10:34:15.921407Z","iopub.execute_input":"2025-05-16T10:34:15.921602Z","iopub.status.idle":"2025-05-16T10:34:18.199387Z","shell.execute_reply.started":"2025-05-16T10:34:15.921588Z","shell.execute_reply":"2025-05-16T10:34:18.198845Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Data split\ntrain_df, val_df = train_test_split(df, test_size=0.15, stratify=df[\"label\"], random_state=42)\n\n# Generators\nIMG_SIZE = 224\ntrain_gen = ImageDataGenerator(rescale=1./255, rotation_range=15, horizontal_flip=True, zoom_range=0.2)\nval_gen = ImageDataGenerator(rescale=1./255)\n\ntrain_data = train_gen.flow_from_dataframe(train_df, x_col=\"image_path\", y_col=\"label\", target_size=(IMG_SIZE, IMG_SIZE), class_mode='sparse', batch_size=32)\nval_data = val_gen.flow_from_dataframe(val_df, x_col=\"image_path\", y_col=\"label\", target_size=(IMG_SIZE, IMG_SIZE), class_mode='sparse', batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T10:34:18.200617Z","iopub.execute_input":"2025-05-16T10:34:18.200855Z","iopub.status.idle":"2025-05-16T10:34:20.289513Z","shell.execute_reply.started":"2025-05-16T10:34:18.200813Z","shell.execute_reply":"2025-05-16T10:34:20.288686Z"}},"outputs":[{"name":"stdout","text":"Found 8512 validated image filenames belonging to 7 classes.\nFound 1503 validated image filenames belonging to 7 classes.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Model builder\ndef build_model(base):\n    base_model = base(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    base_model.trainable = False\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.3)(x)\n    out = Dense(len(labels), activation='softmax')(x)\n    return Model(inputs=base_model.input, outputs=out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T10:34:20.290392Z","iopub.execute_input":"2025-05-16T10:34:20.290678Z","iopub.status.idle":"2025-05-16T10:34:20.295569Z","shell.execute_reply.started":"2025-05-16T10:34:20.290650Z","shell.execute_reply":"2025-05-16T10:34:20.294877Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Train base models\nmodels = [build_model(base) for base in [EfficientNetB0, MobileNetV2, ResNet50]]\nfor i, model in enumerate(models):\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    print(f\"\\nTraining Model {i+1}\")\n    model.fit(train_data, validation_data=val_data, epochs=7)\n    model.save(f\"model/model_{i}.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T10:34:20.296242Z","iopub.execute_input":"2025-05-16T10:34:20.296449Z","iopub.status.idle":"2025-05-16T11:25:46.829387Z","shell.execute_reply.started":"2025-05-16T10:34:20.296433Z","shell.execute_reply":"2025-05-16T11:25:46.828796Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1747391660.549104      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1747391660.549773      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n\nTraining Model 1\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/7\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1747391687.934114      98 service.cc:148] XLA service 0x7afcfc004530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1747391687.935280      98 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1747391687.935304      98 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1747391689.910977      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/266\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.2578 - loss: 1.8399   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1747391699.426137      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 756ms/step - accuracy: 0.6519 - loss: 1.2127 - val_accuracy: 0.6693 - val_loss: 1.1397\nEpoch 2/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 523ms/step - accuracy: 0.6636 - loss: 1.1691 - val_accuracy: 0.6693 - val_loss: 1.1414\nEpoch 3/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 521ms/step - accuracy: 0.6749 - loss: 1.1301 - val_accuracy: 0.6693 - val_loss: 1.1377\nEpoch 4/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 543ms/step - accuracy: 0.6699 - loss: 1.1520 - val_accuracy: 0.6693 - val_loss: 1.1531\nEpoch 5/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 534ms/step - accuracy: 0.6704 - loss: 1.1548 - val_accuracy: 0.6693 - val_loss: 1.1382\nEpoch 6/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 528ms/step - accuracy: 0.6673 - loss: 1.1649 - val_accuracy: 0.6693 - val_loss: 1.1468\nEpoch 7/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 537ms/step - accuracy: 0.6746 - loss: 1.1425 - val_accuracy: 0.6693 - val_loss: 1.1345\n\nTraining Model 2\nEpoch 1/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 557ms/step - accuracy: 0.6371 - loss: 1.1909 - val_accuracy: 0.7119 - val_loss: 0.8201\nEpoch 2/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 527ms/step - accuracy: 0.7094 - loss: 0.8214 - val_accuracy: 0.7226 - val_loss: 0.7731\nEpoch 3/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 530ms/step - accuracy: 0.7309 - loss: 0.7693 - val_accuracy: 0.7152 - val_loss: 0.8013\nEpoch 4/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 530ms/step - accuracy: 0.7353 - loss: 0.7628 - val_accuracy: 0.7359 - val_loss: 0.7327\nEpoch 5/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 526ms/step - accuracy: 0.7422 - loss: 0.7324 - val_accuracy: 0.7379 - val_loss: 0.7498\nEpoch 6/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 524ms/step - accuracy: 0.7400 - loss: 0.7233 - val_accuracy: 0.7432 - val_loss: 0.7216\nEpoch 7/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 523ms/step - accuracy: 0.7478 - loss: 0.7076 - val_accuracy: 0.7392 - val_loss: 0.7300\n\nTraining Model 3\nEpoch 1/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 563ms/step - accuracy: 0.6394 - loss: 1.2548 - val_accuracy: 0.6693 - val_loss: 1.1507\nEpoch 2/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 527ms/step - accuracy: 0.6730 - loss: 1.1432 - val_accuracy: 0.6693 - val_loss: 1.1290\nEpoch 3/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 529ms/step - accuracy: 0.6710 - loss: 1.1400 - val_accuracy: 0.6693 - val_loss: 1.1173\nEpoch 4/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 525ms/step - accuracy: 0.6657 - loss: 1.1469 - val_accuracy: 0.6693 - val_loss: 1.1081\nEpoch 5/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 508ms/step - accuracy: 0.6701 - loss: 1.1242 - val_accuracy: 0.6687 - val_loss: 1.1027\nEpoch 6/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 510ms/step - accuracy: 0.6866 - loss: 1.0905 - val_accuracy: 0.6693 - val_loss: 1.1200\nEpoch 7/7\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 526ms/step - accuracy: 0.6723 - loss: 1.1248 - val_accuracy: 0.6693 - val_loss: 1.1075\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Ensemble\ninput_layer = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\noutputs = [models[i](input_layer) for i in range(3)]\navg_output = Average()(outputs)\nensemble_model = Model(inputs=input_layer, outputs=avg_output)\nensemble_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nensemble_model.save(\"ensemble_skin_classifier.h5\")\nprint(\"✅ Saved ensemble_skin_classifier.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:25:46.830261Z","iopub.execute_input":"2025-05-16T11:25:46.830491Z","iopub.status.idle":"2025-05-16T11:25:47.739073Z","shell.execute_reply.started":"2025-05-16T11:25:46.830473Z","shell.execute_reply":"2025-05-16T11:25:47.738343Z"}},"outputs":[{"name":"stdout","text":"✅ Saved ensemble_skin_classifier.h5\n","output_type":"stream"}],"execution_count":13}]}