{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = 128\n\n# Load metadata\ndf = pd.read_csv(\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\")\n\n# Encode labels\nle = LabelEncoder()\ndf['label'] = le.fit_transform(df['dx'])  # dx contains diagnosis class names\nlabels = to_categorical(df['label'])\n\n# Image directories\nimage_dir1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1/\"\nimage_dir2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2/\"\n\n# Load and resize images\nimages = []\nfor img_id in df['image_id']:\n    path = os.path.join(image_dir1, img_id + \".jpg\")\n    if not os.path.exists(path):\n        path = os.path.join(image_dir2, img_id + \".jpg\")\n    img = cv2.imread(path)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    images.append(img)\n\nimages = np.array(images) / 255.0  # Normalize pixel values\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    images, labels, test_size=0.2, random_state=42, stratify=labels\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def transformer_block(inputs, num_heads=2, ff_dim=128, dropout=0.1):\n    # Layer Norm + Multi-Head Attention\n    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n    x = layers.MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(x, x)\n    x = layers.Dropout(dropout)(x)\n    res = x + inputs\n\n    # Layer Norm + Feedforward\n    x = layers.LayerNormalization(epsilon=1e-6)(res)\n    x = layers.Dense(ff_dim, activation='relu')(x)\n    x = layers.Dropout(dropout)(x)\n    x = layers.Dense(inputs.shape[-1])(x)\n\n    return x + res\n\ndef build_model(input_shape=(128, 128, 3), num_classes=7):\n    base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n    base_model.trainable = True  # Freeze base model for now\n\n    inputs = layers.Input(shape=input_shape)\n    x = base_model(inputs)\n    x = layers.Reshape((-1, x.shape[-1]))(x)  # Prepare for transformer (patch sequence)\n    x = transformer_block(x)  # One lightweight transformer block\n    x = layers.GlobalAveragePooling1D()(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n\n    return models.Model(inputs, outputs)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = build_model()\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # Lower LR for fine-tuning\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntrain_gen = datagen.flow(X_train, y_train, batch_size=16)\n\nhistory = model.fit(\n    train_gen,\n    validation_data=(X_test, y_test),\n    epochs=30,\n    verbose=1\n)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"skin_cancer_model.h5\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow.keras.backend as K\nimport matplotlib.cm as cm\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        [model.inputs], \n        [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        class_channel = predictions[:, pred_index]\n\n    grads = tape.gradient(class_channel, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get last conv layer name\nfor layer in reversed(model.layers):\n    if isinstance(layer, tf.keras.layers.Conv2D):\n        print(\"Last Conv Layer:\", layer.name)\n        break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def display_gradcam(image, model, label_map, true_label, last_conv_layer_name=\"Conv_1\"):\n    img_array = np.expand_dims(image, axis=0)\n\n    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\n    # Convert to RGB and resize heatmap to image size\n    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n\n    heatmap_color = cm.jet(heatmap / 255.0)[:, :, :3]\n    heatmap_color = np.uint8(255 * heatmap_color)\n\n    superimposed_img = heatmap_color * 0.4 + image * 255\n    superimposed_img = np.uint8(superimposed_img)\n\n    plt.figure(figsize=(6, 6))\n    plt.imshow(superimposed_img)\n    plt.title(f\"True: {label_map[true_label]} | Predicted: {label_map[np.argmax(model.predict(img_array))]}\")\n    plt.axis('off')\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check layer names inside MobileNetV2\nfor layer in model.get_layer(\"mobilenetv2_1.00_128\").layers:\n    if isinstance(layer, tf.keras.layers.Conv2D):\n        print(layer.name)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Map back label index to class name\nlabel_map = dict(zip(range(len(le.classes_)), le.classes_))\n\n# Pick any image\nidx = 10\ntest_img = X_test[idx]\ntrue_label = np.argmax(y_test[idx])\n\ndisplay_gradcam(test_img, model, label_map, true_label, last_conv_layer_name=\"mobilenetv2_1.00_128/block_16_project\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}