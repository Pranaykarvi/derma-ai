{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install necessary packages (run once)\n!pip install timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:42:49.549078Z","iopub.execute_input":"2025-05-17T14:42:49.549326Z","iopub.status.idle":"2025-05-17T14:43:59.706731Z","shell.execute_reply.started":"2025-05-17T14:42:49.549303Z","shell.execute_reply":"2025-05-17T14:43:59.705981Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->timm) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->timm) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom timm import create_model\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:43:59.708543Z","iopub.execute_input":"2025-05-17T14:43:59.708753Z","iopub.status.idle":"2025-05-17T14:44:10.285279Z","shell.execute_reply.started":"2025-05-17T14:43:59.708729Z","shell.execute_reply":"2025-05-17T14:44:10.284535Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# === Constants ===\nIMG_SIZE = 224\nBATCH_SIZE = 16  # Adjust based on RAM/GPU memory\nEPOCHS = 10\nNUM_CLASSES = 7\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:10.285971Z","iopub.execute_input":"2025-05-17T14:44:10.286424Z","iopub.status.idle":"2025-05-17T14:44:10.348753Z","shell.execute_reply.started":"2025-05-17T14:44:10.286398Z","shell.execute_reply":"2025-05-17T14:44:10.348190Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# === Dataset class ===\nclass HAM10000Dataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row['image_path']\n        label = row['label_encoded']\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:10.349623Z","iopub.execute_input":"2025-05-17T14:44:10.349883Z","iopub.status.idle":"2025-05-17T14:44:10.366804Z","shell.execute_reply.started":"2025-05-17T14:44:10.349864Z","shell.execute_reply":"2025-05-17T14:44:10.366078Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# === Load metadata and prepare dataframe ===\nmetadata_path = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\nimg_dir_1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\"\nimg_dir_2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\"\n\nmetadata = pd.read_csv(metadata_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:10.368551Z","iopub.execute_input":"2025-05-17T14:44:10.368739Z","iopub.status.idle":"2025-05-17T14:44:10.412168Z","shell.execute_reply.started":"2025-05-17T14:44:10.368724Z","shell.execute_reply":"2025-05-17T14:44:10.411700Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Combine image directories into one column of full paths\ndef get_image_path(row):\n    fname = row['image_id'] + \".jpg\"\n    path1 = os.path.join(img_dir_1, fname)\n    path2 = os.path.join(img_dir_2, fname)\n    if os.path.exists(path1):\n        return path1\n    elif os.path.exists(path2):\n        return path2\n    else:\n        return None\n\nmetadata['image_path'] = metadata.apply(get_image_path, axis=1)\nmetadata = metadata.dropna(subset=['image_path'])  # Remove missing images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:10.412822Z","iopub.execute_input":"2025-05-17T14:44:10.413010Z","iopub.status.idle":"2025-05-17T14:44:29.709885Z","shell.execute_reply.started":"2025-05-17T14:44:10.412995Z","shell.execute_reply":"2025-05-17T14:44:29.709372Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Map labels to integers\nle = LabelEncoder()\nmetadata['label_encoded'] = le.fit_transform(metadata['dx'])\n\nprint(\"Classes and their encoded labels:\")\nprint(dict(zip(le.classes_, le.transform(le.classes_))))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:29.710517Z","iopub.execute_input":"2025-05-17T14:44:29.710704Z","iopub.status.idle":"2025-05-17T14:44:29.717669Z","shell.execute_reply.started":"2025-05-17T14:44:29.710689Z","shell.execute_reply":"2025-05-17T14:44:29.716820Z"}},"outputs":[{"name":"stdout","text":"Classes and their encoded labels:\n{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# === Data split ===\ntrain_df, test_df = train_test_split(metadata, test_size=0.2, stratify=metadata['label_encoded'], random_state=42)\ntrain_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df['label_encoded'], random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:29.718547Z","iopub.execute_input":"2025-05-17T14:44:29.718777Z","iopub.status.idle":"2025-05-17T14:44:29.748008Z","shell.execute_reply.started":"2025-05-17T14:44:29.718758Z","shell.execute_reply":"2025-05-17T14:44:29.747540Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# === Transformations ===\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:29.748629Z","iopub.execute_input":"2025-05-17T14:44:29.748937Z","iopub.status.idle":"2025-05-17T14:44:29.753393Z","shell.execute_reply.started":"2025-05-17T14:44:29.748920Z","shell.execute_reply":"2025-05-17T14:44:29.752755Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# === Dataset and DataLoader ===\ntrain_ds = HAM10000Dataset(train_df, transform=train_transform)\nval_ds = HAM10000Dataset(val_df, transform=val_transform)\ntest_ds = HAM10000Dataset(test_df, transform=val_transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\ntest_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n# === Model Setup ===\nmodel = create_model('swin_tiny_patch4_window7_224', pretrained=True, num_classes=NUM_CLASSES)\nmodel.to(DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:29.754069Z","iopub.execute_input":"2025-05-17T14:44:29.754287Z","iopub.status.idle":"2025-05-17T14:44:31.078809Z","shell.execute_reply.started":"2025-05-17T14:44:29.754263Z","shell.execute_reply":"2025-05-17T14:44:31.078186Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1973a55135a848b09f71d4ef38af8d7b"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"SwinTransformer(\n  (patch_embed): PatchEmbed(\n    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n  )\n  (layers): Sequential(\n    (0): SwinTransformerStage(\n      (downsample): Identity()\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): Identity()\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=96, out_features=384, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=384, out_features=96, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): Identity()\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=96, out_features=288, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=96, out_features=96, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.009)\n          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=96, out_features=384, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=384, out_features=96, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.009)\n        )\n      )\n    )\n    (1): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=384, out_features=192, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.018)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=192, out_features=768, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=768, out_features=192, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.018)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=192, out_features=576, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=192, out_features=192, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.027)\n          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=192, out_features=768, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=768, out_features=192, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.027)\n        )\n      )\n    )\n    (2): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=768, out_features=384, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.036)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.036)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.045)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.045)\n        )\n        (2): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.055)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.055)\n        )\n        (3): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.064)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.064)\n        )\n        (4): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.073)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.073)\n        )\n        (5): SwinTransformerBlock(\n          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=384, out_features=384, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.082)\n          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.082)\n        )\n      )\n    )\n    (3): SwinTransformerStage(\n      (downsample): PatchMerging(\n        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n      )\n      (blocks): Sequential(\n        (0): SwinTransformerBlock(\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.091)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.091)\n        )\n        (1): SwinTransformerBlock(\n          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (attn): WindowAttention(\n            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=768, out_features=768, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n            (softmax): Softmax(dim=-1)\n          )\n          (drop_path1): DropPath(drop_prob=0.100)\n          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n            (act): GELU(approximate='none')\n            (drop1): Dropout(p=0.0, inplace=False)\n            (norm): Identity()\n            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path2): DropPath(drop_prob=0.100)\n        )\n      )\n    )\n  )\n  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (head): ClassifierHead(\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n    (drop): Dropout(p=0.0, inplace=False)\n    (fc): Linear(in_features=768, out_features=7, bias=True)\n    (flatten): Identity()\n  )\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# === Loss and Optimizer ===\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-4)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:31.079470Z","iopub.execute_input":"2025-05-17T14:44:31.079694Z","iopub.status.idle":"2025-05-17T14:44:31.084457Z","shell.execute_reply.started":"2025-05-17T14:44:31.079678Z","shell.execute_reply":"2025-05-17T14:44:31.083790Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# === Training Loop ===\ndef train_one_epoch(model, dataloader, criterion, optimizer):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    for inputs, labels in tqdm(dataloader):\n        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:31.085218Z","iopub.execute_input":"2025-05-17T14:44:31.085483Z","iopub.status.idle":"2025-05-17T14:44:31.099799Z","shell.execute_reply.started":"2025-05-17T14:44:31.085468Z","shell.execute_reply":"2025-05-17T14:44:31.099279Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in tqdm(dataloader):\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * inputs.size(0)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    return epoch_loss, epoch_acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:31.100568Z","iopub.execute_input":"2025-05-17T14:44:31.100776Z","iopub.status.idle":"2025-05-17T14:44:31.119377Z","shell.execute_reply.started":"2025-05-17T14:44:31.100759Z","shell.execute_reply":"2025-05-17T14:44:31.118744Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"best_val_acc = 0\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)\n    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n    \n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), 'best_swin_model.pth')\n        print(\"Saved Best Model\")\n    scheduler.step()\n\nprint(f\"Training complete! Best validation accuracy: {best_val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T14:44:31.121173Z","iopub.execute_input":"2025-05-17T14:44:31.121387Z","iopub.status.idle":"2025-05-17T14:55:55.009925Z","shell.execute_reply.started":"2025-05-17T14:44:31.121363Z","shell.execute_reply":"2025-05-17T14:55:55.008918Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:05<00:00,  6.86it/s]\n100%|██████████| 51/51 [00:07<00:00,  6.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7270 | Train Acc: 0.7477\nVal Loss: 0.6122 | Val Acc: 0.7618\nSaved Best Model\n\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.16it/s]\n100%|██████████| 51/51 [00:04<00:00, 10.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5280 | Train Acc: 0.8058\nVal Loss: 0.6002 | Val Acc: 0.7656\nSaved Best Model\n\nEpoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.17it/s]\n100%|██████████| 51/51 [00:04<00:00, 10.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.4153 | Train Acc: 0.8528\nVal Loss: 0.4281 | Val Acc: 0.8491\nSaved Best Model\n\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.17it/s]\n100%|██████████| 51/51 [00:04<00:00, 10.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.3390 | Train Acc: 0.8734\nVal Loss: 0.4459 | Val Acc: 0.8429\n\nEpoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.18it/s]\n100%|██████████| 51/51 [00:05<00:00, 10.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.2785 | Train Acc: 0.9017\nVal Loss: 0.4810 | Val Acc: 0.8516\nSaved Best Model\n\nEpoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.18it/s]\n100%|██████████| 51/51 [00:04<00:00, 10.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1500 | Train Acc: 0.9472\nVal Loss: 0.3326 | Val Acc: 0.8815\nSaved Best Model\n\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.18it/s]\n100%|██████████| 51/51 [00:04<00:00, 11.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.1054 | Train Acc: 0.9614\nVal Loss: 0.3395 | Val Acc: 0.8766\n\nEpoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.17it/s]\n100%|██████████| 51/51 [00:04<00:00, 10.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0846 | Train Acc: 0.9699\nVal Loss: 0.3607 | Val Acc: 0.8890\nSaved Best Model\n\nEpoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.17it/s]\n100%|██████████| 51/51 [00:04<00:00, 10.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0684 | Train Acc: 0.9764\nVal Loss: 0.3400 | Val Acc: 0.8978\nSaved Best Model\n\nEpoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 451/451 [01:02<00:00,  7.16it/s]\n100%|██████████| 51/51 [00:04<00:00, 11.00it/s]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0550 | Train Acc: 0.9821\nVal Loss: 0.3863 | Val Acc: 0.8878\nTraining complete! Best validation accuracy: 0.8978\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14}]}